name: setup-ai-server
description: "Setup AI server for testing"

runs:
  using: composite
  steps:
    - name: Cache ollama
      id: cache-ollama
      uses: actions/cache@v4
      with:
        path: /usr/share/ollama/.ollama/models/
        key: ollama

    - name: Install ollama
      shell: bash
      run: curl -fsSL https://ollama.com/install.sh | sh 
    
    - name: Start ollama
      if: steps.cache-ollama.outputs.cache-hit != 'true'
      shell: bash
      run: ollama pull tinydolphin
  
    - name: Start litellm
      shell: bash
      run: poetry run litellm --config llm_assistant/ollama/test_proxy_config.yaml &
           